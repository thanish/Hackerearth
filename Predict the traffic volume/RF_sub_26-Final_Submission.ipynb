{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RF_sub_26 - 99.97876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BTHANISH\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import datetime as datetime\n",
    "import bamboolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF_train = pd.read_csv('Train.csv')\n",
    "DF_test  = pd.read_csv('Test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33750, 15)\n",
      "(33664, 15)\n",
      "(33664, 15) (14454, 15)\n",
      "(48118, 15)\n"
     ]
    }
   ],
   "source": [
    "#Dropping some outliers compared to test\n",
    "print(DF_train.shape)\n",
    "DF_train = DF_train.loc[((DF_train.rain_p_h < 11) & (DF_train.temperature !=0)),]\n",
    "#DF_train = DF_train.loc[((DF_train.temperature !=0)),]\n",
    "print(DF_train.shape)\n",
    "\n",
    "# Combining the train and test\n",
    "DF_test['traffic_volume'] = np.nan\n",
    "print(DF_train.shape, DF_test.shape)\n",
    "DF_prod = pd.concat([DF_train, DF_test])\n",
    "print(DF_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48118, 15)\n",
      "(48115, 15)\n"
     ]
    }
   ],
   "source": [
    "# Dropping the outliers\n",
    "print(DF_prod.shape)\n",
    "DF_prod = DF_prod.loc[DF_prod.rain_p_h != DF_prod.rain_p_h.max(),]\n",
    "print(DF_prod.shape)\n",
    "\n",
    "#Correcting the date format\n",
    "DF_prod['date_time'] = pd.to_datetime(DF_prod.date_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2)\n",
      "(48115, 15)\n",
      "(48115, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None                         46706\n",
       "Labor Day                      157\n",
       "Washingtons Birthday           136\n",
       "Thanksgiving Day               135\n",
       "Memorial Day                   134\n",
       "New Years Day                  131\n",
       "Christmas Day                  131\n",
       "Independence Day               126\n",
       "Veterans Day                   120\n",
       "State Fair                     120\n",
       "Columbus Day                   112\n",
       "Martin Luther King Jr Day      107\n",
       "Name: is_holiday, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extending the holiday to the entire day\n",
    "temp = DF_prod.loc[DF_prod.is_holiday != 'None', ['date_time','is_holiday']]\n",
    "temp['date_time'] = temp['date_time'].dt.date\n",
    "temp = temp.loc[~temp.duplicated(),]\n",
    "print(temp.shape)\n",
    "temp.head()\n",
    "\n",
    "print(DF_prod.shape)\n",
    "#Merging it to the dataframe\n",
    "DF_prod = DF_prod.merge(temp, how = 'left', \n",
    "                            left_on = [DF_prod['date_time'].dt.date], \n",
    "                            right_on = ['date_time']).drop(['date_time', 'date_time_y', 'is_holiday_x'], axis = 1).rename(columns = {'date_time_x' : 'date_time', \n",
    "                                                                                                                                     'is_holiday_y' : 'is_holiday'})\n",
    "print(DF_prod.shape)\n",
    "DF_prod.loc[DF_prod.is_holiday.isnull(), ['is_holiday']] = 'None'\n",
    "DF_prod.is_holiday.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DF = DF_prod.copy()\n",
    "DF['day'] = DF.date_time.dt.day\n",
    "DF['month'] = DF.date_time.dt.month\n",
    "DF['hour'] = DF.date_time.dt.hour\n",
    "DF['weekday_number'] = DF.date_time.dt.dayofweek\n",
    "DF['week_number'] = DF.date_time.dt.week\n",
    "DF['weekday'] = np.where(DF.date_time.dt.dayofweek < 5, 1, 0)\n",
    "DF['holiday'] = np.where(DF.is_holiday == 'None', 0, 1)\n",
    "\n",
    "DF['weekday_plus_holiday'] = np.where((DF['weekday'] + DF['holiday']) == 2, 1 ,0)\n",
    "DF['wind_direction_NSEW'] = np.where((DF.wind_direction >= 0) & (DF.wind_direction < 90) , 'North_East', \n",
    "                                    np.where((DF.wind_direction >= 90) & (DF.wind_direction < 180) , 'South_East', \n",
    "                                            np.where((DF.wind_direction >= 180) & (DF.wind_direction < 270) , 'South_West', 'North_West')))\n",
    "\n",
    "DF['seasons'] = np.where(DF.date_time.dt.month.isin([3,4,5]),'Spring',\n",
    "                         np.where(DF.date_time.dt.month.isin([6,7,8]),'Summer',\n",
    "                                  np.where(DF.date_time.dt.month.isin([9,10,11]),'Fall','Winter')))\n",
    "#DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['peak_hour']= np.where(((DF.hour>=6) & (DF.hour<=8)) | ((DF.hour>=15) & (DF.hour<=17)), 1, 0)\n",
    "\n",
    "day_time_start = datetime.time(6,00,00)\n",
    "afternoon_time_start = datetime.time(11,00,00)\n",
    "evening_start_time = datetime.time(15,00,00)\n",
    "night_time_start = datetime.time(20,00,00)\n",
    "\n",
    "DF['part_of_day'] = np.where(((DF['date_time'].dt.time > day_time_start) & (DF['date_time'].dt.time <= afternoon_time_start)), 0, \n",
    "                             np.where(((DF['date_time'].dt.time > afternoon_time_start) & (DF['date_time'].dt.time <= evening_start_time)), 1, \n",
    "                                     np.where(((DF['date_time'].dt.time > evening_start_time) & (DF['date_time'].dt.time <= night_time_start)), 2, 3)))  \n",
    "\n",
    "day_light_start = datetime.time(6,00,00)\n",
    "night_time_start = datetime.time(20,00,00)\n",
    "DF['Day_light'] = np.where(((DF['date_time'].dt.time >= day_light_start) & (DF['date_time'].dt.time <= night_time_start)), 1, 0)\n",
    "\n",
    "\n",
    "DF['temperature_lag_1'] = DF.temperature.shift(1)\n",
    "\n",
    "#DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48115, 2)\n",
      "(1860, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BTHANISH\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Next day and previous day holiday\n",
    "temp = DF[['date_time', 'holiday']]\n",
    "temp['date_time'] = temp['date_time'].dt.date\n",
    "temp = temp.loc[~temp.duplicated(),]\n",
    "temp['previous_day_holiday'] = temp['holiday'].shift(1)\n",
    "temp['next_day_holiday'] = temp['holiday'].shift(-1)\n",
    "\n",
    "DF = DF.merge(temp[['date_time', 'previous_day_holiday', 'next_day_holiday']], \n",
    "              how = 'left', left_on = [DF['date_time'].dt.date], \n",
    "              right_on = ['date_time']).drop(['date_time', 'date_time_y'], axis = 1).rename(columns = {'date_time_x' : 'date_time'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat columns\n",
      "Index(['weather_type', 'weather_description', 'is_holiday',\n",
      "       'wind_direction_NSEW', 'seasons'],\n",
      "      dtype='object')\n",
      "Num columns\n",
      "Index(['Day_light', 'air_pollution_index', 'clouds_all', 'date_time', 'day',\n",
      "       'dew_point', 'holiday', 'hour', 'humidity', 'month', 'next_day_holiday',\n",
      "       'part_of_day', 'peak_hour', 'previous_day_holiday', 'rain_p_h',\n",
      "       'snow_p_h', 'temperature', 'temperature_lag_1', 'traffic_volume',\n",
      "       'visibility_in_miles', 'week_number', 'weekday', 'weekday_number',\n",
      "       'weekday_plus_holiday', 'wind_direction', 'wind_speed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_columns = DF.select_dtypes(include = ['object']).columns\n",
    "num_columns = DF.columns.difference(cat_columns)\n",
    "print(\"Cat columns\")\n",
    "print(cat_columns)\n",
    "print(\"Num columns\")\n",
    "print(num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling the null values with -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF[num_columns] = DF[num_columns].fillna(-999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  weather_type weather_description is_holiday wind_direction_NSEW seasons\n",
      "0       Clouds    scattered clouds       None          North_West    Fall\n",
      "1       Clouds       broken clouds       None          North_West    Fall\n",
      "2       Clouds     overcast clouds       None          North_West    Fall\n",
      "3       Clouds     overcast clouds       None          North_West    Fall\n",
      "4       Clouds       broken clouds       None          North_West    Fall\n",
      "   weather_type  weather_description  is_holiday  wind_direction_NSEW  seasons\n",
      "0             1                   24           7                    1        0\n",
      "1             1                    2           7                    1        0\n",
      "2             1                   19           7                    1        0\n",
      "3             1                   19           7                    1        0\n",
      "4             1                    2           7                    1        0\n"
     ]
    }
   ],
   "source": [
    "LE = LabelEncoder()\n",
    "print(DF[cat_columns].head())\n",
    "DF[cat_columns] = DF[cat_columns].apply(lambda x : LE.fit_transform(x))\n",
    "print(DF[cat_columns].head())\n",
    "\n",
    "# DF = pd.get_dummies(DF)\n",
    "# DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns, select columns for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Day_light', 'air_pollution_index', 'clouds_all', 'day', 'dew_point',\n",
      "       'holiday', 'hour', 'humidity', 'is_holiday', 'month',\n",
      "       'next_day_holiday', 'part_of_day', 'peak_hour', 'previous_day_holiday',\n",
      "       'rain_p_h', 'seasons', 'temperature', 'temperature_lag_1',\n",
      "       'weather_description', 'weather_type', 'week_number', 'weekday',\n",
      "       'weekday_number', 'weekday_plus_holiday', 'wind_direction',\n",
      "       'wind_direction_NSEW', 'wind_speed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ignore_columns = ['date_time', 'visibility_in_miles', 'snow_p_h'\n",
    "                  #, 'holiday', 'weekday_plus_holiday', 'is_holiday'\n",
    "                 ]\n",
    "dep = 'traffic_volume'\n",
    "drop = np.append(np.array(ignore_columns), np.array([dep]))\n",
    "indep = DF.columns.difference(drop)\n",
    "print(indep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (33661, 31) Test shape (14454, 31)\n",
      "(20276, 31) (13385, 31)\n",
      "\n",
      "2013    8545\n",
      "2014    4824\n",
      "2015    4348\n",
      "2012    2559\n",
      "Name: date_time, dtype: int64\n",
      "2016    9285\n",
      "2017    4100\n",
      "Name: date_time, dtype: int64\n",
      "2018    7949\n",
      "2017    6505\n",
      "Name: date_time, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#train_test_split\n",
    "train_prod = DF.loc[DF.traffic_volume != -999,]\n",
    "test_prod = DF.loc[DF.traffic_volume == -999,]\n",
    "print('Train shape', train_prod.shape, 'Test shape', test_prod.shape)\n",
    "\n",
    "# Validation period\n",
    "train_local = train_prod.loc[train_prod.date_time.dt.year <= 2015,]\n",
    "test_local  = train_prod.loc[train_prod.date_time.dt.year > 2015,]\n",
    "\n",
    "print(train_local.shape, test_local.shape)\n",
    "print(\"\")\n",
    "print(train_local.date_time.dt.year.value_counts()) \n",
    "print(test_local.date_time.dt.year.value_counts())\n",
    "print(test_prod.date_time.dt.year.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 459.80545516391885\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "RF = RandomForestRegressor(n_estimators = 120, max_depth= 15, \n",
    "                          min_samples_leaf = 4\n",
    "                          )\n",
    "RF.fit(train_local[indep], train_local[dep])\n",
    "RF_predict = RF.predict(test_local[indep])\n",
    "print('RMSE', np.sqrt(mean_squared_error(RF_predict, test_local[dep])))\n",
    "\n",
    "#RF_prod_predict = RF.predict(test_prod[indep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day_light</td>\n",
       "      <td>0.639173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.191295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>weekday_number</td>\n",
       "      <td>0.054260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>weekday</td>\n",
       "      <td>0.042205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>peak_hour</td>\n",
       "      <td>0.022880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>week_number</td>\n",
       "      <td>0.007730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>weekday_plus_holiday</td>\n",
       "      <td>0.006844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>holiday</td>\n",
       "      <td>0.006328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>temperature</td>\n",
       "      <td>0.004566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day</td>\n",
       "      <td>0.003868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>temperature_lag_1</td>\n",
       "      <td>0.003154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>seasons</td>\n",
       "      <td>0.002536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>part_of_day</td>\n",
       "      <td>0.002257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is_holiday</td>\n",
       "      <td>0.001581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>wind_direction</td>\n",
       "      <td>0.001561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>humidity</td>\n",
       "      <td>0.001504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>month</td>\n",
       "      <td>0.001433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>wind_speed</td>\n",
       "      <td>0.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_pollution_index</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>previous_day_holiday</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>weather_description</td>\n",
       "      <td>0.000647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rain_p_h</td>\n",
       "      <td>0.000623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clouds_all</td>\n",
       "      <td>0.000615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dew_point</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>next_day_holiday</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>weather_type</td>\n",
       "      <td>0.000521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>wind_direction_NSEW</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>long_weekend</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature       imp\n",
       "0              Day_light  0.639173\n",
       "6                   hour  0.191295\n",
       "23        weekday_number  0.054260\n",
       "22               weekday  0.042205\n",
       "13             peak_hour  0.022880\n",
       "21           week_number  0.007730\n",
       "24  weekday_plus_holiday  0.006844\n",
       "5                holiday  0.006328\n",
       "17           temperature  0.004566\n",
       "3                    day  0.003868\n",
       "18     temperature_lag_1  0.003154\n",
       "16               seasons  0.002536\n",
       "12           part_of_day  0.002257\n",
       "8             is_holiday  0.001581\n",
       "25        wind_direction  0.001561\n",
       "7               humidity  0.001504\n",
       "10                 month  0.001433\n",
       "27            wind_speed  0.001145\n",
       "1    air_pollution_index  0.000996\n",
       "14  previous_day_holiday  0.000694\n",
       "19   weather_description  0.000647\n",
       "15              rain_p_h  0.000623\n",
       "2             clouds_all  0.000615\n",
       "4              dew_point  0.000600\n",
       "11      next_day_holiday  0.000574\n",
       "20          weather_type  0.000521\n",
       "26   wind_direction_NSEW  0.000269\n",
       "9           long_weekend  0.000141"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_imp = pd.DataFrame({ 'Feature' : indep, 'imp' : RF.feature_importances_}).sort_values(['imp'], ascending = False)\n",
    "RF_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 269.5930043762874\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "RF = RandomForestRegressor(n_estimators = 120, max_depth= 15, \n",
    "                           min_samples_leaf = 4)\n",
    "RF.fit(train_prod[indep], train_prod[dep])\n",
    "RF_predict = RF.predict(test_local[indep])\n",
    "print('RMSE', np.sqrt(mean_squared_error(RF_predict, test_local[dep])))\n",
    "\n",
    "RF_prod_predict = RF.predict(test_prod[indep])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_sub = pd.DataFrame({'date_time': test_prod['date_time'],\n",
    "                       'traffic_volume' : RF_prod_predict})\n",
    "RF_sub.to_csv('RF_sub_26.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
